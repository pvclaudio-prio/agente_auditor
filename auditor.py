import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import openai
import json
import time
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
import seaborn as sns

# --------------------------
# ConfiguraÃ§Ãµes da pÃ¡gina
# --------------------------
st.set_page_config(
    page_title="AnÃ¡lise de Pagamentos",
    page_icon="ðŸ’°",
    layout="wide"
)

st.title("ðŸ’° AnÃ¡lise Inteligente de Pagamentos")
st.markdown("Aplicativo para clusterizaÃ§Ã£o, detecÃ§Ã£o de red flags e revisÃ£o inteligente com IA.")

# Configurar chave da OpenAI
openai.api_key = st.secrets["openai"]["api_key"]

def preprocessar_base(df: pd.DataFrame):
    """
    ðŸ”§ FunÃ§Ã£o robusta de prÃ©-processamento:
    - Limpa nomes de colunas
    - Remove espaÃ§os, quebras e caracteres invisÃ­veis
    - Converte possÃ­veis colunas numÃ©ricas armazenadas como texto
    - Remove colunas 100% nulas
    - Remove linhas totalmente vazias
    - Remove colunas duplicadas (se houver)

    âœ… Retorna:
    - DataFrame limpo
    - Lista de colunas numÃ©ricas detectadas
    """

    st.subheader("ðŸ§½ Executando prÃ©-processamento da base")

    # ðŸ”— Limpeza dos nomes das colunas
    df.columns = df.columns.str.strip().str.replace('\n', '').str.replace('\r', '').str.replace('\t', '')

    # ðŸ” Remover colunas 100% nulas
    colunas_nulas = df.columns[df.isnull().all()].tolist()
    if colunas_nulas:
        st.warning(f"âš ï¸ As seguintes colunas foram removidas por serem 100% nulas: {colunas_nulas}")
        df = df.drop(columns=colunas_nulas)

    # ðŸ” Remover linhas totalmente vazias
    linhas_vazias = df.isnull().all(axis=1).sum()
    if linhas_vazias > 0:
        st.warning(f"âš ï¸ {linhas_vazias} linhas totalmente vazias foram removidas.")
        df = df.dropna(how='all')

    # ðŸ” Remover colunas duplicadas
    if df.columns.duplicated().any():
        st.warning("âš ï¸ Foram encontradas colunas duplicadas e elas foram removidas.")
        df = df.loc[:, ~df.columns.duplicated()]

    # ðŸ”§ Tentativa de conversÃ£o forÃ§ada para numÃ©rico
    df_converted = df.copy()
    for col in df.columns:
        df_converted[col] = pd.to_numeric(df[col], errors='ignore')

    # ðŸ” Detectar colunas numÃ©ricas
    colunas_numericas = df_converted.select_dtypes(include=['float64', 'int64', 'float32', 'int32']).columns.tolist()

    if not colunas_numericas:
        st.warning("âš ï¸ Nenhuma coluna foi detectada como numÃ©rica inicialmente. Tentando forÃ§ar a conversÃ£o...")

        for col in df.columns:
            df_converted[col] = pd.to_numeric(df[col], errors='coerce')

        colunas_numericas = df_converted.select_dtypes(include=['float64', 'int64', 'float32', 'int32']).columns.tolist()

    if not colunas_numericas:
        st.error("ðŸš« Nenhuma coluna numÃ©rica encontrada apÃ³s o prÃ©-processamento.")
    else:
        st.success(f"âœ… Colunas numÃ©ricas detectadas: {colunas_numericas}")

    return df_converted, colunas_numericas

# --------------------------
# Definindo abas
# --------------------------
st.sidebar.image("PRIO_SEM_POLVO_PRIO_PANTONE_LOGOTIPO_Azul.png")
aba = st.sidebar.radio(
    "ðŸ“‹ Menu",
    ["ðŸ—ï¸ AnÃ¡lise ML", "ðŸ¤– Agente IA", "ðŸ“¥ Download"]
)

# --------------------------
# Aba 1 - AnÃ¡lise Tradicional
# --------------------------
if aba == "ðŸ—ï¸ AnÃ¡lise ML":
    st.header("ðŸ—ï¸ ClusterizaÃ§Ã£o + ClassificaÃ§Ã£o + Red Flag")

    uploaded_file = st.file_uploader("ðŸ“¤ FaÃ§a upload da base de pagamentos (Excel)", type=["xlsx"])

    if uploaded_file is not None:
        df_raw = pd.read_excel(uploaded_file, engine='openpyxl')
    
        # âœ… Executa o prÃ©-processamento
        df, colunas_numericas = preprocessar_base(df_raw)
    
        if not colunas_numericas:
            st.stop()  # Interrompe execuÃ§Ã£o se nÃ£o houver colunas numÃ©ricas

        st.subheader("ðŸ“„ PrÃ©-visualizaÃ§Ã£o da base")
        st.dataframe(df.head())

        st.subheader("ðŸ§  AnÃ¡lise de Peso Inicial das VariÃ¡veis")

        # ðŸ” Seleciona colunas numÃ©ricas automaticamente
        colunas_numericas = df.select_dtypes(include=['float64', 'int64']).columns.tolist()

        if not colunas_numericas:
            st.error("âš ï¸ Nenhuma coluna numÃ©rica encontrada para anÃ¡lise.")
            st.stop()

        # ðŸ”§ Padroniza os dados
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(df[colunas_numericas])

        # ðŸ“Š Calcula a variÃ¢ncia de cada coluna
        variancias = np.var(X_scaled, axis=0)
        peso_colunas = variancias / variancias.sum()

        df_pesos = pd.DataFrame({
            'Feature': colunas_numericas,
            'Peso (%)': peso_colunas * 100
        }).sort_values(by="Peso (%)", ascending=False)

        st.dataframe(df_pesos)

        # ðŸ“ˆ GrÃ¡fico das importÃ¢ncias
        fig_pesos = px.bar(
            df_pesos,
            x='Feature',
            y='Peso (%)',
            title="ðŸ“Š Peso EstatÃ­stico Inicial das VariÃ¡veis",
            text_auto='.2f'
        )
        st.plotly_chart(fig_pesos, use_container_width=True)

        st.markdown("---")
        st.subheader("ðŸŽ¯ Selecione as colunas para clusterizaÃ§Ã£o e classificaÃ§Ã£o")

        selected_columns = st.multiselect(
            "Selecione as colunas com maior relevÃ¢ncia para o modelo",
            colunas_numericas,
            default=df_pesos['Feature'].head(5).tolist()  # Sugere as top 5 como padrÃ£o
        )

        if selected_columns:
            st.success(f"Colunas selecionadas: {selected_columns}")

            # ðŸ”§ PadronizaÃ§Ã£o novamente para apenas as selecionadas
            X_scaled = scaler.fit_transform(df[selected_columns])

            # ðŸ” AvaliaÃ§Ã£o do melhor nÃºmero de clusters
            st.subheader("ðŸ”¢ AvaliaÃ§Ã£o AutomÃ¡tica do NÃºmero de Clusters")

            sil_scores = []
            inertias = []
            k_range = range(2, 10)

            for k in k_range:
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                kmeans.fit(X_scaled)
                labels = kmeans.labels_
                sil = silhouette_score(X_scaled, labels)
                sil_scores.append(sil)
                inertias.append(kmeans.inertia_)

            # Plot Elbow + Silhouette
            fig, ax1 = plt.subplots()

            color = 'tab:blue'
            ax1.set_xlabel('NÃºmero de Clusters')
            ax1.set_ylabel('Inertia (Elbow)', color=color)
            ax1.plot(k_range, inertias, marker='o', color=color)
            ax1.tick_params(axis='y', labelcolor=color)

            ax2 = ax1.twinx()

            color = 'tab:green'
            ax2.set_ylabel('Silhouette Score', color=color)
            ax2.plot(k_range, sil_scores, marker='x', linestyle='--', color=color)
            ax2.tick_params(axis='y', labelcolor=color)

            st.pyplot(fig)

            # ðŸ† Melhor nÃºmero de clusters
            melhor_k = k_range[sil_scores.index(max(sil_scores))]
            st.success(f"ðŸ“ˆ NÃºmero sugerido de clusters: **{melhor_k}**")

            k_selecionado = st.number_input(
                "Ajuste manual do nÃºmero de clusters (opcional)",
                min_value=2,
                max_value=10,
                value=melhor_k,
                step=1
            )

            # ðŸš€ ClusterizaÃ§Ã£o
            kmeans = KMeans(n_clusters=k_selecionado, random_state=42, n_init=10)
            clusters = kmeans.fit_predict(X_scaled)
            df['Cluster'] = clusters

            # ðŸ“Š PCA para visualizaÃ§Ã£o
            st.subheader("ðŸ“Š VisualizaÃ§Ã£o dos Clusters")
            pca = PCA(n_components=2)
            components = pca.fit_transform(X_scaled)
            df_plot = pd.DataFrame(components, columns=['Componente 1', 'Componente 2'])
            df_plot['Cluster'] = clusters.astype(str)

            fig = px.scatter(
                df_plot,
                x="Componente 1",
                y="Componente 2",
                color="Cluster",
                title="DistribuiÃ§Ã£o dos Clusters",
                width=800,
                height=500
            )
            st.plotly_chart(fig, use_container_width=True)

            # ðŸ”¥ ImportÃ¢ncia Real das Features com Random Forest
            st.subheader("ðŸ› ï¸ ImportÃ¢ncia Real das Features")

            rf = RandomForestClassifier(random_state=42)
            rf.fit(X_scaled, clusters)

            importances = rf.feature_importances_
            feature_importance = pd.DataFrame({
                'Feature': selected_columns,
                'ImportÃ¢ncia': importances
            }).sort_values(by="ImportÃ¢ncia", ascending=False)

            fig_pesos = px.bar(
                feature_importance,
                x="Feature",
                y="ImportÃ¢ncia",
                title="ImportÃ¢ncia das Features (Random Forest)",
                text_auto='.2f'
            )
            st.plotly_chart(fig_pesos, use_container_width=True)

            # ðŸš© ClassificaÃ§Ã£o para Red Flag
            st.subheader("ðŸš© ClassificaÃ§Ã£o Supervisionada para IdentificaÃ§Ã£o de Red Flags")

            red_flag_cluster = st.multiselect(
                "Selecione os clusters que serÃ£o considerados como **Red Flag**",
                options=sorted(df['Cluster'].unique().tolist()),
                default=[max(df['Cluster'])]
            )

            df['Red Flag'] = df['Cluster'].apply(lambda x: 'Sim' if x in red_flag_cluster else 'NÃ£o')

            st.dataframe(df.head())

            # âœ”ï¸ Salvar no session_state para a Aba 2
            st.session_state['df_redflag'] = df

            st.download_button(
                label="ðŸ’¾ Baixar base com Red Flags (Aba 1)",
                data=df.to_csv(index=False, sep=";", encoding='utf-8-sig'),
                file_name="base_red_flag_aba1.csv",
                mime='text/csv'
            )

# --------------------------
# Aba 2 - Agente GPT-4o com IA Real Robusto
# --------------------------
elif aba == "ðŸ¤– Agente IA":
    st.header("ðŸ¤– Agente de IA - RevisÃ£o dos Red Flags")

    if 'df_redflag' not in st.session_state:
        st.warning("âš ï¸ A base de Red Flags ainda nÃ£o foi gerada. Por favor, execute a Aba 1 antes de usar esta aba.")
        st.stop()

    df_base = st.session_state['df_redflag'].copy()

    st.subheader("ðŸ“„ Base com Red Flags (Aba 1)")
    st.dataframe(df_base.head())

    # ðŸ” Filtros
    st.subheader("ðŸ”Ž Filtros para execuÃ§Ã£o do agente")

    col1, col2, col3 = st.columns(3)

    with col1:
        filtro_redflag = st.selectbox(
            "Red Flag",
            ["Todos", "Sim", "NÃ£o"]
        )

    with col2:
        fornecedores_unicos = sorted(df_base["Fornecedor"].dropna().unique().tolist()) if "Fornecedor" in df_base.columns else []
        filtro_fornecedor = st.multiselect(
            "Fornecedor",
            fornecedores_unicos,
            default=fornecedores_unicos
        )

    with col3:
        if "Data" in df_base.columns:
            df_base["Data"] = pd.to_datetime(df_base["Data"], errors='coerce')
            data_min = df_base["Data"].min().date()
            data_max = df_base["Data"].max().date()
            filtro_periodo = st.date_input(
                "PerÃ­odo:",
                [data_min, data_max]
            )
        else:
            filtro_periodo = None

    # Aplicar filtros
    df_filtrado = df_base.copy()

    if filtro_redflag != "Todos":
        df_filtrado = df_filtrado[df_filtrado['Red Flag'] == filtro_redflag]

    if filtro_fornecedor:
        df_filtrado = df_filtrado[df_filtrado['Fornecedor'].isin(filtro_fornecedor)]

    if filtro_periodo:
        data_inicio, data_fim = filtro_periodo
        df_filtrado = df_filtrado[
            (df_filtrado["Data"].dt.date >= data_inicio) &
            (df_filtrado["Data"].dt.date <= data_fim)
        ]

    st.markdown(f"ðŸ”¸ **{len(df_filtrado)} registros encontrados apÃ³s aplicaÃ§Ã£o dos filtros.**")
    st.dataframe(df_filtrado.head())

    # ðŸ’° Estimativa de Custo
    st.subheader("ðŸ’° Estimativa de Custo")

    tokens_estimados_por_linha = 150  # AproximaÃ§Ã£o mÃ©dia
    custo_por_1000_tokens = 0.01  # Custo aproximado GPT-4o

    total_tokens = len(df_filtrado) * tokens_estimados_por_linha
    custo_estimado = (total_tokens / 1000) * custo_por_1000_tokens

    st.info(f"ðŸ”¢ Tokens estimados: {total_tokens} tokens")
    st.info(f"ðŸ’° Custo estimado: **USD {custo_estimado:.4f}**")

    executar = st.button(f"ðŸš€ Executar Agente GPT-4o para {len(df_filtrado)} registros")

    if executar:
        st.info("ðŸ”§ O agente estÃ¡ analisando os dados. Isso pode levar alguns minutos...")

        resultados = []
        progresso = st.progress(0)

        for idx, (i, row) in enumerate(df_filtrado.iterrows()):
            try:
                dados = row.dropna().to_dict()

                prompt = f"""
                VocÃª Ã© um auditor especialista em compliance e anÃ¡lise de pagamentos corporativos.

                Analise o seguinte lanÃ§amento de pagamento extraÃ­do do SAP:

                {dados}

                Este lanÃ§amento foi previamente classificado como Red Flag = {row.get('Red Flag', 'Desconhecido')}.

                Com base nas informaÃ§Ãµes apresentadas, responda:
                1. Se o Red Flag deve ser mantido ("Sim") ou removido ("NÃ£o").
                2. O motivo da sua decisÃ£o, de forma objetiva, clara e tÃ©cnica.

                Responda no formato JSON:
                {{
                  "Red Flag Revisado": "Sim ou NÃ£o",
                  "Motivo": "explicaÃ§Ã£o detalhada"
                }}
                """

                response = openai.ChatCompletion.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0
                )

                resposta = response.choices[0].message.content.strip()

                try:
                    resposta_json = json.loads(resposta)
                    red_flag_revisado = resposta_json.get("Red Flag Revisado", "NÃ£o")
                    motivo = resposta_json.get("Motivo", "Motivo nÃ£o identificado.")
                except json.JSONDecodeError:
                    red_flag_revisado = "NÃ£o"
                    motivo = f"Erro no parsing da resposta: {resposta}"

                resultados.append({
                    **dados,
                    "Red Flag": row.get('Red Flag', ''),
                    "Red Flag Revisado": red_flag_revisado,
                    "Motivo": motivo
                })

                progresso.progress((idx + 1) / len(df_filtrado))

                time.sleep(1)  # Delay opcional para evitar rate limit

            except Exception as e:
                st.error(f"Erro ao processar linha {i}: {e}")
                resultados.append({
                    **row.to_dict(),
                    "Red Flag Revisado": "Erro",
                    "Motivo": f"Erro na execuÃ§Ã£o do agente: {e}"
                })
                continue

        progresso.empty()

        df_final = pd.DataFrame(resultados)

        st.success("âœ… AnÃ¡lise do agente concluÃ­da.")
        st.dataframe(df_final.head())

        st.session_state['df_final'] = df_final

# --------------------------
# Aba 3 - Download Final
# --------------------------
elif aba == "ðŸ“¥ Download":
    st.header("ðŸ“¥ Download da Base Consolidada")

    if 'df_final' in st.session_state:
        st.subheader("ðŸ—‚ï¸ Base Consolidada com Red Flags e Motivos")
        st.dataframe(st.session_state['df_final'].head())

        st.download_button(
            label="ðŸ’¾ Baixar Base Final",
            data=st.session_state['df_final'].to_csv(index=False).encode('utf-8-sig'),
            file_name="base_pagamentos_final.csv",
            mime='text/csv'
        )
    else:
        st.warning("âš ï¸ Nenhuma base gerada ainda. Por favor, execute as etapas na Aba 1 e Aba 2.")


